# ZomatoBangloreRestaurant
Data analysis on the zomato Banglore Restaurant Dataset

Banglore is an Indian city which is also known as India's IT capital. As a huge and fast-developing city, it is occupied with more than 12,000 restaurants where there is a massive availability of different dishes across the world. One major fact regarding this city is that the demand for restaurants is increasing per day due to the high dependency that people living there have on restaurant food. This is because of the insufficiency in time for cooking. Zomato is a great platform and website for choosing a restaurant and ordering food. It helps people to attain an overview of different nearby restaurants and the foods available there along with their pictures, ratings, and reviews posted by other customers. A restaurant with a good rating indicates the success and popularity of that restaurant because of the tasty food and the quality of service. It also attracts a lot of people which further increases the popularity of the restaurant. All these made ratings available on this website to be an important feature for the restaurant owners to be careful about, as a bad review may harm the restaurant which could result in the loss of many orders. The new entrepreneurs are now facing a bit difficult situation to complete with the existing restaurants as most existing restaurants serve the same kind of food. This made it important for the new entrepreneurs to understand the demography of restaurant location and analyze the food types in a locality to find the most popular one, does the whole people in a locality prefers a particular cuisine, etc. This analysis can be made using factors like the location of the restaurant, the average expense for the food for two people, etc. In this project, the aim is to predict the rating of new restaurants based on factors like an average cost for two people, locality of the restaurants, the votes obtained for the restaurants, cuisines, etc. The rating ranges from one to 5. This project also aims to perform an exploratory data analysis on the restaurants of Bangalore to find out the most expensive restaurants and the most reliable ones where reliability is counted based on the ratings, votes and the cost for a meal for two people. 

The different steps performed during analysis are:
1) Data Cleaning: The data is partially cleaned using the tool called `OpenRefine` where many irrelevant columns were removed and some columns like `approximate_cost_for_two_people`, `Located_in_city` and `located_in_type` were renamed to `average_cost`, `locality` and `restaurant_type`. Type conversion to `integer` was also performed on the column `votes`. The trailing `/5` from the column `rate` was removed and the unwanted `commas` from columns `average_cost` and `votes` were removed
2) Partially cleaned data is then loaded t databricks to perform the rest of the operations. A function was created to calculate null values of diffrent columns, where the presence of clumn `dish_liked` with more than half of the values being null was obserevd. The column `dish_liked` was removed from the data set and the mean values for the columns `average_cost` and `rate` was calculated to fill the empty files of those columns with their corresponding mean value. Afterwards, the complex values like `NEW` and `-` was removed from the column `rate`. The final step performed as part of the data cleaning process was to change the type of columns `rate` and `average_cost` from string to float
3) Exploratory Data Analysis: Aftre the cleaning operations. an exploratory data analysis was performed on the data set t find out the featires that have most impact in rating prediction. It was found that rating have high dependence on features location, average_cost,online_order, book_table, rest_type, cuisines and votes.
4)Feature Transformation: As there were categorical values in some features , lable indexing was made on the values that are categorical using `String Indexer`. To generate vectors from the lable indexed values, `OneHotEncoding` was perfomed and finally the `VectorAssembler` was used to merge all the vectors along with the numerical values. This generated a column called `features` where all the features that can be used for modelling was combined and a column valled `label` that conatined the lable for predictio. The entire process of feature transformation was performed using `pipelines`
5)Train/Test: The data set was divided for training and testing purpose, where 70% of the total data was assigned for training purpose and the rest was assigned for testing purpose
6)Model Creation and Impelementation: The Logistic Regression, decision Tree and Random Forest algorithms were used to create the model using the training data. The test for predicting the restaurant rating was performed on the testing data were the modek created using the decision tree algorithm outperfromed the other two models. The accuracy of prediction made by diffrent models were measured by finding the are under ROC Curve
7)Data Visualization:
